# Redshift AI Ops

## Goal:## Live Data Processing and Insights Production Ready

1. Data is generated by DCY (Data Centre Yes) during Business as usual
2. Feature abstraction occurs as part of a DAG designed in Airflow (including calculated fields)
3. Loglizer interprets log data 
4. Data transformation is handled by a separate service
5. The redshiftAIOps Machine Learning model (JWTLive) is hosted on  the DCY using a Kubernetes cluser. it offers an endpoint through PyNest to receive and process log data
6. Data is stored in ElasticSearch with a fixed schema
7. Data is returned to DCY after authentication by Cloudflare service hosted on DCY, along with Authentik private service
8. The JWTLive model is trained once a significant shift in underlying distribution of data occurs. Or Once a Month. Training happens in the Cloud Using a Lambda in AWS to triggr the action. Or, in a parallel overnight fashion on DCY.
9. Results are displayed on a Kibana Dashboard
10. Logs from the model are stored in the Elastic Search Database.


# Developer Notes
1. The current state of files is maintained.
2. Data version control is managed by DVC
3. Model parameters etc is manager by ML flow
4. Any new FOSS developer will  receive a copy of the official RedShift Ops Docker Image in a standardized environment
